{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3b9d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "from additional_info import sub_dir, json_reader, json_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fd38eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_dataset = \"coco\"\n",
    "\n",
    "# to get limit size of sample output \n",
    "output_line_limit = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66819d48",
   "metadata": {},
   "source": [
    "# 1. Initializing dataset directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a143a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory containing image and annotations of coco dataset\n",
    "image_dir = os.path.join(sub_dir['dir_data'], selected_dataset, \"train2017\")\n",
    "annotation_dir = os.path.join(sub_dir['dir_data'], selected_dataset, \"annotations\")\n",
    "\n",
    "print(f\"Image directory = {image_dir}\")\n",
    "print(f\"Annotation directory = {annotation_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556b5c31",
   "metadata": {},
   "source": [
    "# 2. Number of files in image and annotation directory [first look]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ae5911",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir_files = os.listdir(image_dir)\n",
    "print(f\"Number of images = \", len(image_dir_files))\n",
    "print(f\"Number of annotation files  = \", len(os.listdir(annotation_dir)))\n",
    "\n",
    "print(\"\\nSome files from image folder and their size :: \")\n",
    "for i,file in enumerate(image_dir_files):\n",
    "    file_size = round((os.path.getsize(os.path.join(image_dir, file)))/1024, ndigits=2)\n",
    "    print(\"\\t{}. File name = {} :: size = {} kb\".format(i+1, file, file_size))\n",
    "    \n",
    "    if i > output_line_limit:\n",
    "        print(\"\\t....................................................\\n\"*3)\n",
    "        file_size = round((os.path.getsize(os.path.join(image_dir, image_dir_files[-1])))/1024, ndigits=2)\n",
    "        print(\"\\t{}. File name = {} :: size = {} kb\".format(len(image_dir_files), image_dir_files[-1], file_size))\n",
    "        break\n",
    "        \n",
    "print(\"\\nFiles from annotation folder :: \")\n",
    "for i,file in enumerate(os.listdir(annotation_dir)):\n",
    "    file_size = round((os.path.getsize(os.path.join(annotation_dir, file)))/1024, ndigits=2)\n",
    "    print(\"\\t{}. File name = {} :: size = {} kb\".format(i+1, file, file_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5583c5",
   "metadata": {},
   "source": [
    "### As we have downloaded train images from the coco dataset for EDA, we only require instances_train2017.json file. So, we will be working with these two things from now on:\n",
    "\n",
    "- **image_dir** = contains 118287 images from coco dataset\n",
    "\n",
    "- **annotation** = contains all the information (which we will read below) from the **instances_train2017.json** [largest file present in annotation folder, **448 MB**]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136c9dc3",
   "metadata": {},
   "source": [
    "# 3. Viewing annotation file [\"instances_train2017.json\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544c0b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading contents of \"instances_train2017.json\" into annotation\n",
    "annotation = json_reader(os.path.join(annotation_dir,\"instances_train2017.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acfc2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As annotation is a json file i.e. a dictionary structure, lets take a look at keys present in it.\n",
    "print(\"Keys present in annotaion = \", annotation.keys())\n",
    "\n",
    "# Lets see the number of entries in each key and first value of each key, for better understanding.\n",
    "for i,key in enumerate(annotation.keys()):\n",
    "    print(f\"\\n{i+1}. Key = {key}\\n\\t Number of entries :: {len(annotation[key])}\")\n",
    "    if type(annotation[key]) == list:\n",
    "        print(\"\\t First value :: \")\n",
    "        pprint(annotation[key][0],indent=25)\n",
    "    else:\n",
    "        print(\"\\t First value :: \")\n",
    "        pprint(annotation[key],indent=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9150599",
   "metadata": {},
   "source": [
    "### Annotation consists of five sections of information that provide information for the entire dataset. [source: https://cocodataset.org/#format-data]\n",
    "- **info**     – general information about the dataset.\n",
    "\n",
    "- **licenses** – license information for the images in the dataset.\n",
    "\n",
    "- **images**   – a list of images in the dataset.\n",
    "\n",
    "- **annotations** – a list of annotations (including bounding boxes) that are present in all images in the dataset.\n",
    "\n",
    "- **categories**  – a list of label categories.\n",
    "\n",
    "    ### Structure of images in annotations[\"images\"]\n",
    "    - **id**         – A unique identifier for the image. The id field maps to the id field in the annotations array (where bounding box information is stored).\n",
    "\n",
    "    - **license**    – Maps to the license array.\n",
    "\n",
    "    - **coco_url**   – The location of the image.\n",
    "\n",
    "    - **flickr_url** – The location of the image on Flickr.\n",
    "\n",
    "    - **width**      – The width of the image.\n",
    "\n",
    "    - **height**     – The height of the image.\n",
    "\n",
    "    - **file_name**  – The image file name. In this example, file_name and id match, but this is not a requirement for COCO datasets.\n",
    "\n",
    "    - **date_captured** – the date and time the image was captured.\n",
    "    \n",
    "    ### Structure of annotations in annotations[\"annotations\"]\n",
    "    - **id** – The identifier for the annotation.\n",
    "\n",
    "    - **image_id** –  Corresponds to the image id in the images array.\n",
    "\n",
    "    - **category_id** –  The identifier for the label that identifies the object within a bounding box. It maps to the id field of the categories array.\n",
    "\n",
    "    - **iscrowd** – Specifies if the image contains a crowd of objects.\n",
    "\n",
    "    - **segmentation** – Segmentation information for objects on an image.\n",
    "\n",
    "    - **area** – The area of the annotation.\n",
    "\n",
    "    - **bbox** –  Contains the coordinates, in pixels, of a bounding box around an object on the image. **[top left x, top left y,width,height]**\n",
    "    ### Structure of categories in annotation[\"categories\"]\n",
    "    - **supercategory** – The parent category for a label.\n",
    "\n",
    "    - **id** – The label identifier. The id field maps to the category_id field in an annotation object.\n",
    "\n",
    "    - **name** – the label name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c13c1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
